动态内存分配器比低级的mmap和munmap函数来创建和删除虚拟内存区域更为方便

动态内存分配器维护着一个进程内的虚拟内存区域，叫做堆。堆是请求二进制零页面，从零开始增长（向更高的地址，栈是向更低的地址增长）。并且内核为每一个进程维护一个brk，它指向堆的顶部

**分配器将堆视为一组不同大小的块的集合来维护，每个块就是一个连续虚拟内存片**，要么是已分配的（已缓存和未缓存），要么是空闲的。一个空闲块一直保持为空闲状态，直到被分配，一个已分配块一直保持分配状态直到被释放，根据被释放的情况可以将分配器分成两类：

1. **显式分配器**：要求**应用**显式地释放掉已分配的块，例如C中用malloc分配的块，最后要用free来释放；C++中用new分配的块，要用delete释放
2. **隐式分配器**：要求**分配器**主动检测一个已分配的块何时不再被程序所使用，那么就释放这个块。隐式分配器有个更熟悉的名字——垃圾收集器



### malloc 和 free 函数

1. malloc程序包是由C标准库提供的显式分配器：

```c
#include <stdlib.h>
void *malloc(size_t size);
```

malloc函数会返回一个指针，指向大小**至少**为size字节的字节块，为什么是至少，因为malloc分配的块会做对齐，比如一个双字（8个字节）的对齐要求，当size为7字节时，实际分配的内存块为8个字节

+ 当malloc申请的内存块比可用的虚拟内存还大时就会返回NULL并设置errno
+ malloc不会初始化内存块，对应的calloc会初始化内存块为0
+ 用realloc改变一个已分配块的大小

2. sbrk函数通过将内核的brk指针增加incr来拓展和伸缩堆，incr为正数则为拓展，为负则为伸缩

   ```c
   #include <unistd.h>
   void *sbrk(intptr_t incr);
   ```

3. free函数用于释放已分配的块

   ```c
   #include <stdlib.h>
   void free(void *ptr);
   ```

   ptr必须指向一个从malloc、calloc或者realloc分配的块的起始位置，否则free的行为就是没有定义的。并且free函数什么也不返回，什么也不设置，对于出错的时候这是很糟

下图示例了malloc和free函数如何处理一个16字节的堆，每个小方格代表一个字（4字节）

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230220165253491.png" alt="image-20230220165253491" style="zoom:67%;" />

### 为什么使用动态内存分配

在程序中，通常有运行时才知道一个数据结构大小的情况，如果不用动态内存分配，就必须在开始就分配一个绝对够大的空间，这对于程序很多时候是一种浪费，而用动态内存就能灵活分配



### 分配器的要求和目标

#### 要求

1. 处理任意请求序列：分配器不能假设释放顺序就是按照分配顺序
2. 立即响应请求：分配器不能为了提高性能堆请求进行重新排列
3. 只使用堆
4. 对齐要求
5. 不修改已分配的块



#### 目标

1. 最大化吞吐率：吞吐率的定义为单元时间内完成的请求数。例如，一个分配器在1秒内处理了500个分配请求和500个释放请求，那么它的吞吐率就是每秒1000个操作。一般而言，我们可以通过让**分配和释放请求的平均时间最小化来实现吞吐率最大化**
2. 最大化内存利用率：尽可能地在分配过程中减少碎片出现的现象



### 碎片

1. 内部碎片：一个已分配块比所请求的块大小更大，通常是由于对齐要求而出现。内部碎片的量化是简单明了的，它就是已分配块大小和它们的有效载荷的差，内部碎片的数量只取决于**以前请求模式和分配器的实现方式**

2. 外部碎片：是指当空闲内存**合计**起来足够满足一个分配请求，但是没有一个**单独**的空闲内存块能单独满足，例如下面的例子中，有一个8字节的分配请求，此时堆内合计的空闲内存刚好有8字节，但是被分成了两个空闲块，所以这个分配请求是失败的

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230220170847999.png" alt="image-20230220170847999" style="zoom: 50%;" />

   外部碎片的量化更为困难，因为它不仅仅取决于以前的请求模式和分配器的实现方式，还受将来的请求方式影响。就拿上面的例子，只要之后的请求块小于等于6字节，就不会出现外部碎片的情况。

   正因为外部碎片的不能预测，所以分配器的实现通过采用启发式策略



### 实现问题

在一个极端情况下，分配器不重复使用任何块，malloc就按照顺序来分配，这种情况下的吞吐率会很好，但是内存利用率会极低。如何实现两者的平衡？必须考虑下面的问题：

1. 空闲块怎么记录？
2. 放置策略：选择哪一个空闲块放置？
3. 分割：将一个新分配的块放置在某个空闲块后，如何处理剩下的部分？
4. 合并：如何处理刚刚释放的块？



#### 隐式空闲链表

用于解决记录空闲块的问题

分配器需要一种数据结构来区别块的边界，区别空闲块和已分配块，大多数分配器将这些信息嵌入块本身。

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230220171811045.png" alt="image-20230220171811045" style="zoom: 67%;" />

在这种情况下，一个块的组成如下：

+ **头部(Block Size)**：四字节大小，原本用于记录块中有效载荷的大小，如果我们强加8字节的对齐要求，那么块的大小就是8的倍数，那么块的大小的**低三位**总是0，因此我们只需要内存大小的前29位，剩下的3位可用于编码其他信息。这种情况下，我们就用其中的最低位（已分配位）来指明这个块是已分配的还是空闲的
+ **有效载荷(Payload)**
+ **填充块(Padding)**：用于对付外部碎片，也可以用于满足对齐需求

这种块格式下，堆被组织成一个连续的已分配块和空闲块的序列：

 ![image-20230220172350681](https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230220172350681.png)

我们称这种结构位**隐式空闲链表**，是因为空闲块是通过头部中的大小字段**隐含**地连接在一起，通过大小字段就能找到下一个块的位置。因此分配器可以以这种方式遍历堆中的所有块，注意最后有一个**设置了分配位但是大小为零的终止头部**的特殊块作为结束块。

隐式空闲链表的缺点就是搜索时间与空闲块成线性关系，在申请块时实际返回的块还要加上头部大小和可能的填充部分。



#### 放置已分配的块

当应用请求一个k字节的块时，分配器搜索空闲链表，查找一个足够大可以放置所请求块的空闲块。分配器执行这种搜索的方式是由放置策略决定的：

1. 首次适配：从头开始，选择第一个合适的空闲块
2. 下一次适配：从上一次查询结束的地方开始，选择第一个合适的空闲块
3. 最佳适配：检查每一个空闲块，选择合适的**最小空闲块**

一些数据表明，下一次适配的内存率其实比首次适配更低，最佳适配的内存利用率最高，其吞吐率也就更低



#### 分割空闲块

分配器为请求找到一个合适的空闲块后，要根据实际情况做出决定：

1. 利用整个空闲块：缺点是产生内部碎片，如果能为后续请求产生好的匹配这也是可行的
2. 分割



#### 获取额外堆内存

如果分配器没有找到合适的空闲块怎么办？

1. 进行空闲块合并
2. 如果合并后也没有，那就通过调用sbrk函数向内核申请额外的堆内存，分配器会将其作为一个大的块插入到空闲块链表中



#### 合并空闲块

1. 为什么要合并空闲块

当分配器释放一个已分配块时，可能有其他空闲块和这个新释放的空闲块相邻。这些空闲块相邻造成**假碎片**的现象，就是许多可用的空闲块被分隔成小的、无法使用的空闲块。比如下例，中间有两个有效载荷为3个字的空闲块相邻，但是缺无法容纳4字节的请求

![image-20230220193139179](https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230220193139179.png)

2. 为了解决这个问题，分配器有两种合并方式：

   1. 立即合并：每次一个块被释放的时候，就合并所有相邻的空闲块

   2. 推迟合并：直到某个分配请求失败了，就扫描整个堆，合并空闲块

      立即合并虽然可以在常数时间内完成，但在一些特定场景下会产生一种抖动，快速的分配器通常采用的是推迟合并



#### 带边界标记的合并

1. 背景

   上面讲了分配器合并空闲块的方式，那么分配器是如何合并的呢？我们假设当前要释放的块为当前块，当前块的头部指向下一个块，我们只需要检查下一个块的头部看其是空闲的还是已分配，如果是空闲的，就把它的大小简单地加上当前块的头部上，这在常数时间就能完成

   能合并当前块下一个的块，对于上一个块呢？通常做法是从头遍历整个空闲块链表，并且记录前面块的位置，直到到达当前块。对于隐式空闲链表的方式，每次free的耗时都和堆的大小成线性关系，还能继续优化吗？

2. 优化

   knuth提出的边界标记就能在常数时间内完成前面块的合并，这种思想是在每个块的尾部也加上一个和头部一模一样的**尾部**，结构如图所示：

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230220194402020.png" alt="image-20230220194402020" style="zoom:67%;" />

   那么分配器就可以通过检查前面块的脚部，而知道前面块的起始位置（根据块的大小往前推），考虑所有可能的情况：

   1. 两个相邻的块都是已分配，所以不会合并，只是修改当前块状态为空闲
   2. 当前块和后面的块合并，用两个块大小的和来更新当前块的头部和后面块的尾部
   3. 当前块和前面块合并，用两个块大小的和来更新前面块的头部和当前块的尾部
   4. 当前块和上下两个块都合并，用三个块的大小更新前面块的头部和后面块的尾部

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230220194607416.png" alt="image-20230220194607416" style="zoom: 67%;" />

   这种方式也存在其缺点，尾部的增加再次增大了块地隐形开销







