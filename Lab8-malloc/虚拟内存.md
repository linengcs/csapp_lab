**虚拟内存的能力**

1. 它将主存看成是一个存储在地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式来高效使用主存（DRAM）
2. 它为每个进程提供了一致的地址空间，从而简化了内存管理
3. 它保护了每个进程的地址空间不被其他进程破坏



### 物理和虚拟地址

计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组，每个字节都有**唯一的物理地址**。CPU访问内存的最自然的方式就是使用物理地址，早期的计算机使用物理寻址，现代使用的是虚拟寻址。

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216143847401.png" alt="image-20230216143847401" style="zoom: 67%;" />

使用虚拟地址，cpu通过生成一个虚拟地址(Virtual Address, VA)来访问主存，这个虚拟地址在被送入Main memory之前会由CPU芯片上的内存管理单元（Memory Management Unit，MMU）利用存在主存中的查询表完成地址翻译（Address translation），该表的内容由操作系统管理.



### 虚拟内存作为缓存的工具

1. **虚拟内存在哪？**

   虚拟内存被组织为一个由存放在**磁盘**上的N个连续的字节大小的单元组成的数组。每个字节都有**唯一的虚拟地址**，作为到数组的索引。磁盘上数组的内容被缓存在DRAM主存中.

2. **如何缓存**

   与**存储器层次结构**缓存一样，磁盘（较低层）上的数据（虚拟内存）被分隔成块，这些块作为磁盘和主存（较高层）之间的传输单元。

   虚拟内存系统将虚拟内存分隔为称为虚拟页（Virtual Page，VP）的**固定大小**来处理这个问题，每个VP的大小为$P=2^p$字节。类似地，物理内存被分隔成物理页（Physical Page， PP），大小也为P字节，物理页也被称为页帧。

3. 虚拟页面的三种状态
   + 未分配的：VM系统还没有分配或创建的VP，未分配的VP没有任何数据与其相关联，也就不占用任何磁盘空间
   + 缓存的：当前已经缓存在主存中的已分配页
   + 未缓存的：未缓存在主存中，但是已经分配了对应的物理页

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216150320893.png" alt="image-20230216150320893" style="zoom:67%;" />

#### DRAM缓存的组织结构

SRAM缓存位于CPU和主存之间的L1、L2和L3级高速缓存Cache，DRAM缓存表示虚拟内存系统的缓存，它在主存中缓存虚拟页。

根据**存储器层次结构**的知识，对于DRAM缓存的不命中，成本是极其高的，因为DRAM直接与磁盘打交道。正因如此DRAM缓存的组织结构的设计也极为重要：

1. 虚拟页往往很大，通常是4KB-2MB
2. DRAM缓存是全相联的（S=1），即任何虚拟页都可以放置在任何的物理页中
3. DRAM缓存使用了更复杂精密的替换算法
4. DRAM总是采取写回策略（直到被驱逐时才写回），而不是直写



#### 页表

1. **页表的作用**

   判定一个虚拟页是否缓存在DRAM中的某个地方，是的话还能确定其在DRAM中的位置；如果不是，那么该虚拟页在磁盘上的位置也要确定

2. **流程**

   每次MMU做地址翻译的时候都会从**主存**中读取页表，虚拟地址作为索引定位PTE。操作系统负责维护页表的内容，并且在**磁盘和DRAM中传送页**

3. **页表结构**

   ![image-20230216152107417](https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216152107417.png)

   页表是一个页表条目（Page Table Entry，PTE）的数组，**每个PTE由一个有效位和n位地址字段组成**。Valid位为1表示该虚拟页被缓存在DRAM中，并且地址字段就是DRAM相应物理页的起始位置；如果Valid位为0，表示虚拟页还没有缓存在DRAM，如果地址字段为空表示这个虚拟页还没有被分配，否则就是虚拟页未缓存的状态，地址指向该虚拟页在磁盘上的起始位置



#### 缺页

（这段我认为英文原版描述地更为清晰

The CPU has referenced a word in VP 3, which is not cached in DRAM. The address translation hardware reads PTE 3 from memory, infers from the valid bit that VP 3 is not cached, and triggers a page fault exception. The page fault exception **invokes a page fault exception handler** in the kernel, which selects a victim page—in this case, VP 4 stored in PP 3. If VP 4 has been modified, then the kernel copies it back to disk. In either case, the kernel modifies the page table entry for VP 4 to reflect the fact that VP 4 is no longer cached in main memory.

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216153217820.png" alt="image-20230216153217820" style="zoom:67%;" />

Next, the kernel copies VP 3 from disk to PP 3 in memory, updates PTE 3, and then returns. **When the handler returns, it restarts the faulting instruction**, which resends the faulting virtual address to the address translation hardware. But now, VP 3 is cached in main memory, and the page hit is handled normally by the address translation hardware. Figure 9.7 shows the state of our example page table after the page fault.

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216153408989.png" alt="image-20230216153408989" style="zoom:67%;" />

注意！VP3替换掉PP3里的VP4，原来指向PP3里存放VP4的PTE4的表项修改成VP4在外存的地址，而原来PTE3里的表项指向外存里的地址修改为指向PP3的地址，缺页处理程序结束后，返回给引起缺页的指令重新执行，还是会去查找PTE3此时PTE3的valid已经为1，PPN对应PP3

#### 分配页面

操作系统分配一个新的虚拟页时对页表的影响（**malloc的结果**）

VP5的分配过程是在磁盘上创建空间，并且更新PTE5，使其指向磁盘上这个新创建的页面

（分配页面不会将该VP立即缓存到主存中直到被引用）

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216154813389.png" alt="image-20230216154813389" style="zoom: 67%;" />





### 虚拟内存作为内存管理的工具

操作系统为每个进程都提供了一个**独立**的页表，因而也就是一个**独立**的虚拟地址空间。

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216164109766.png" alt="image-20230216164109766" style="zoom:67%;" />

+ 简化链接
+ 简化加载
+ 简化共享
+ 简化内存分配



### 虚拟内存作为内存保护的工具

如何利用虚拟内存来实现用户对数据的读写权限控制呢？

在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问：

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216164448454.png" alt="image-20230216164448454" style="zoom:67%;" />

+ SUP位：表示进程是否必须运行在内核（超级用户）模式下才能访问该页。运行在内核模式下的进程可以访问所有页面，而在用户模式下运行的进程只能访问SUP位为0的页面
+ READ位：表示在可以访问该页面的情况下，是否能读
+ WRITE位：表示在可以访问该页面的情况下，是否能写



### 地址翻译

下图展示了MMU如何利用页表来实现地址翻译

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216165944864.png" alt="image-20230216165944864" style="zoom:67%;" />

CPU中有一个控制寄存器——**页表基址寄存器（Page Table Base Register，PTBR）**指向当前页表（进程）。

1. **解析虚拟地址和物理地址**

   n位的虚拟地址包括p位的虚拟页面偏移VPO，和(n-p)位的虚拟页号VPN，MMU利用VPN来选择适当的PTE，例如VPN0对应PTE0，VPN1选择PTE1，以此类推。将选中的PTE中的物理页号PPN和虚拟地址中的VPO串联起来，就是相应的物理地址PA。注意，这里因为VPO和PPO都是p位所以二者也是相同的。

2. **CPU执行的步骤**

   + **命中**

     1. 处理器Processor生成一个虚拟地址VA发送给MMU
     2. MMU解析出对应PTE的地址发送给高速缓存/主存
     3. 高速缓存/主存把PTE返回给MMU
     4. MMU检查PTE的valid位为1，并联合VPO和PPN构造物理地址PA，转送给高速缓存/主存
     5. 高速缓存/主存将所请求的数传字返回给Processor

     <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216170619071.png" alt="image-20230216170619071" style="zoom:50%;" />

   + **缺页**

     1.  前三步和命中的情况是一样的

     2. MMU检查PTE的valid位为0，MMU触发一次异常，控制传递给CPU的缺页处理程序

     3. 缺页处理程序根据**替换算法**来确定Victim Page，如果该Page已经被修改了，那么就写回到磁盘

     4. 缺页处理程序调入新的页面，并更新内存中的页表

     5. 控制传回引发异常的进程，再次执行**导致缺页的指令**，重复命中的流程

        <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216171014845.png" alt="image-20230216171014845" style="zoom:50%;" />



#### 结合高速缓存和虚拟内存

1. **结合的方式**

    <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216171825335.png" alt="image-20230216171825335" style="zoom: 50%;" />

   因为MMU的地址翻译需要频繁地从主存中读取页表，所以采取将部分页表条目存储在高速缓存SRAM中，以提高翻译效率

2. **MMU如何访问SRAM**

   MMU访问主存DRAM是用的虚拟地址，那么访问SRAM，一般而言是用的物理地址。使用物理地址更为简单地使多个进程访问各自的页表和相同的虚拟页，不必再加一层虚拟地址转换，本末倒置



####  利用TLB加速地址翻译

在上面已经将SRAM与虚拟内存结合，将从主存中读取PTE的周期从几十上百下降到1或2个周期，但仍有许多系统试图消除这个周期。这些系统直接在MMU中增加了一个小型缓存，称为快表（Translation Lookaside Buffer，TLB）

1. **TLB的结构**

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216172821267.png" alt="image-20230216172821267" style="zoom:50%;" />

   TLB是一个小的，虚拟地址的缓存，其中**每一行**都保存了一个PTE组成的块，TLB拥有很高的相联度。如上图所示，用于**组选择和行匹配**的字段是从虚拟地址中的虚拟页号VPN提取出来的。如果TLB有$T=2^t$个组，那么TLB索引（TLBI）是由VPN的最低的t位组成的，而TLB标记（TLBT）则有VPN中剩下的位组成

2. **附加TLB后的地址翻译**

   1. CPU产生一个虚拟地址
   2. MMU从TLB中取中相应的PTE（TLB是虚拟寻址）
   3. MMU利用PTE中的PPN和VA中的VPO串联成物理地址PA，发送给高速缓存/主存
   4. 高速缓存/主存将所请求的数据字返回给CPU

   增加了TLB后整个**地址翻译**的速度是非常快的，因为整个过程都是在MMU中完成

   如果出现TLB miss的情况，MMU会从SRAM中取出相应的PTE，新的PTE存放在TLB中，可能会覆盖一个已经存在的PTE

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216173645369.png" alt="image-20230216173645369" style="zoom:50%;" />



#### 多级页表

1. **如果只有一级页表**

   对于32位的地址空间，4KB的页面和一个4字节的PTE，那么就需要总共$2^{32}/（4*2^{10}）=2^{20}=1M, 1M*4=4MB$大小页表驻留在内存中，如果是64位问题会更复杂

2. **二级页表**

   在32位下，我们构造的二级页表的第一级有1024个PTE，第一级的每个PTE对应1024个二级PTE，每个二级PTE对应一个4KB的页，也就是1024个一级PTE就能覆盖$2^{10}*2^{10}*4KB=4GB$的地址空间

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216200047185.png" alt="image-20230216200047185" style="zoom:67%;" />

   可能会有疑惑，一级1024个PTE，每个一级PTE还对应1024个PTE不也是1M个PTE和一级页表有什么区别呢？

   实际上，如果一级页表是空的，相应的二级页表就根本不会存在，就像上图中的PTE2-7都是空的，也就没有相应的二级PTE，这就代表着巨大的潜在节约，因为对于一个程序而言，4GB的虚拟地址空间的大部分都是未分配的。第二，只有一级页面才总需要在主存中，虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才常驻主存中

3. **k级页表**

   下图是常见的k级页表的地址翻译流程图

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230216200537134.png" alt="image-20230216200537134" style="zoom:67%;" />

   虚拟地址的虚拟页号VPN被划分成k个，每个VPN $i$ 都是一个到第 $i$ 级页表的索引，其中$1 \leq i \leq k$。第 $j$ 级页表的每一个PTE，$1 \leq j \leq k-1$，都指向 $j+1$ 级某个页表的**基址**。第 $k$ 级页表中的每个PTE包含**某个物理页面的PPN**，或者一个磁盘块的地址。

   为了构造物理地址，确定PPN，MMU必须访问k个PTE。这种情况下VPO和PPO也一样。访问k个PTE看上去成本会很高，然而TLB可以将不同层次的页表中常用的PTE都缓存起来，实际并不会比单级页表慢很多，但节约了大量的主存空间。



#### 综合：端到端地址翻译实例

请直接翻看CSAPP3e P573-576（中文版）

整体流程：从给出的虚拟地址中提取VPN，从VPN中再提取TLBI和TLBT，去读取TLB，如果命中，将TLB返回的PPN和VPO结合即可；如果TLB没有命中，则要去主存中取出相应的PTE；之后根据缓存的组数行数和块大小，将物理地址拆分成CO、CI和CT，再从缓存中读取数据字。



### 案例研究

#### Intel Core i7

该处理底层的Haswell微体系结构允许64位的虚拟和物理地址空间，而现在的Core i7实现支持48位（256TB）虚拟地址空间和52位（4PB）物理地址空间，这对目前来说已经完全够用了。（Linux的虚拟内存系统中页的大小为4KB）

1. 介绍了Core i7内存系统的重要部分——处理器封装

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230218204056739.png" alt="image-20230218204056739" style="zoom: 67%;" />

2. 介绍了Core i7的地址翻译情况

   + 层级结构的TLB

   + 层级结构的页表（4层），每一层页表占VPN的9位，也就是有$2^9$个PTE

   + 层次结构的高速缓存L1、L2和L3

   + 其中CR3控制寄存器指向第一级页表的起始位置，CR3的值是每个进程上下文的一部分，每次上下文切换的时候，CR3的值都会被恢复

     <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230218204617440.png" alt="image-20230218204617440" style="zoom:67%;" />

3. 介绍了页表项PTE的格式

   + 每个PTE占8个字节64位
   + 其中有40位是作为指向下一级页表物理基地址（这个地方我有个疑问？在这个例子里每一级页表的每一个PTE都有40位用来下一级页表的基地址，这难道不会很浪费吗？只存一次不就好了吗？）
   + 还有其他位用于权限控制和协助替换算法

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230218205300593.png" alt="image-20230218205300593" style="zoom:67%;" />



#### Linux虚拟内存系统

1. **Linux虚拟内存区域**

   Linux将虚拟内存组织成一些**区域**的集合。一个**区域**就是已经存在着的（已分配的——已缓存和未缓存）虚拟内存的**连续片**，也就是说Linux虚拟内存系统所定义的区域范围是比虚拟页大的，虚拟页是区域的基本单元。这些页是以某种方式相关联的，例如代码段、数据段、堆、共享库段和用户栈都是不同的区域。

   每个存在的虚拟页面都保存在某个区域，而不属于某个区域的虚拟页是不存在的（虚拟页本就是为进程所服务），并且不能被进程引用。内核不用记录这些不存在的虚拟页，能够节省更多的资源

   下图是一个Linux进程等虚拟内存

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230218211727163.png" alt="image-20230218211727163" style="zoom:67%;" />

2. **Linux如何组织虚拟内存**

   内核为**每一个进程**都单独维护一个task_struct，task_struct中的元素包含或者指向内核运行该进程所需的所有信息（例如PID、指向用户栈的指针%rsp，可执行目标文件的名字，程序计数器PC等）

   <img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230218211815499.png" alt="image-20230218211815499" style="zoom:67%;" />

   task_struct中一个条目指向mm_struct，它描述了虚拟内存的当前状态。我们感兴趣的字段有两个，pgd和mmap：

   + pgd指向第一级页表的基址，当内核运行这个进程时就把pgd的值放进CR3寄存器中

   + mmap指向一个vm_area_struct，每一个vm_area_struct都描述了当前虚拟地址空间的**一个区域**

     vm_area_struct的结构如下：

     + vm_start：指向这个区域的起始处
     + vm_end：指向这个区域的结束处
     + vm_prot：描述这个区域内所有页的读写权限
     + vm_flags：描述这个区域内的页面是与其他进程共享的还是私有的
     + vm_next：指向链表的下一个vm_area_struct

3. **Linux缺页异常处理**

   当出现缺页异常，控制将转移到内核的缺页处理程序，处理程序随后执行如下步骤：

   1. 虚拟地址A是合法的吗？即地址A是否在某个vm_area_struct指向的区域内。缺页处理程序通过搜索vm_area_struct的链表，把A和每个vm_area_struct的vm_start和vm_end进行对比来得到结果。如果虚拟地址A不是合法的，就会抛出段错误

      因为一个进程可以创建任意个vm_area_struct，如果通过链表来搜索会造成大量时间损耗，因此在实际中，Linux利用我们看不见的字段建立了一个树，并在这棵树上查看

   2. 试图进行的内存访问是否合法？换句话说进程是否有读写或者执行这个区域内页面的权限？例如，如果缺页是由于一条对代码段中的只读页面进程写操作造成的，处理程序就会抛出段错误

   3. 此刻，内核已经知道这个缺页是由于对合法的虚拟地址进行合法访问造成的。那么处理程序会选择一个牺牲页面，如果牺牲页面被修改了，那么就将它交换出去，换入新的页面并更新页表。当缺页处理程序返回时，CPU重新启动引起缺页的指令





### 内存映射

我们好奇虚拟内存是如何与磁盘上的对象关联起来的。Linux上通过一个叫**内存映射**的过程来实现虚拟内存的初始化，内存映射有两种形式：

1. **Linux文件系统中的普通文件：**一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行文件。文件区被分成页大小（4KB）的片，每一片包含一个虚拟页面的初始内容。因为虚拟页面是按需调度的（已缓存或未缓存），所以这些虚拟页面并没有实际进入物理内存（DRAM），直到CPU第一次引用到页面，即发射一个虚拟地址，触发访问合法地址的合法访问的缺页。

   一个区域的大小如果比文件区要大，那么剩下的就用0填充

2. **匿名文件**：一个区域也可以映射到匿名文件。匿名文件是由内核创建的，包含的全是二进制零。CPU第一次引用这种页面时，内核会在虚拟内存中找到合适的替换页面，如果该页面有修改，那么就换出去，用二进制零覆盖页面并更新页表。注意在这个过程中，磁盘和内存之间没有实际的数据传输，因此映射到匿名文件的区域中的页面也叫**请求二进制零的页**，通常出现在可执行文件的.bss段以及栈和堆，初始长度都是0，特点都是没有和磁盘的数据交互所以就用匿名文件映射。



#### 再看共享对象

内存映射为我们提供了一种清晰的基址，用来控制多个进程如何共享对象

一个对象被映射到虚拟内存的一个区域，可以是共享对象也可以是私有对象，一个进程对一个共享对象的任何写操作其他进程也都会看见，并且会作用在磁盘的原始对象上。

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230219201013031.png" alt="image-20230219201013031" style="zoom:50%;" />

私有对象使用的是一种**写时复制**的技术映射到虚拟内存中，一个私有对象开始生命周期的方式与共享对象一致，在物理内存中只保存有私有对象的一份副本，其中两个进程将一个私有对象映射到它们虚拟内存的不同区域，但是共享这个对象的同一个副本。对于每个映射私有对象的进程，相应私有区域的PTE是标记为只读的，并且vm_area_struct标记为**私有的写时复制**

只要进程没有试图去写它的私有区域，它们就可以继续共享物理内存中对象的一个单独副本，然而只要有一个进程试图写私有区域的某个页面，那么这个写操作就会触发一个保护故障

当故障处理程序发现是由于进程试图写私有区域中一个页面而引发的时，它会在物理内存中新建这个**页面**的新副本（**注意只是页面的副本而不是整个对象**），更新**当前进程**对应页面的PTE指向该新副本（其他进程的页表仍然指向旧的页面），然后将页表的权限改为可写，处理完后控制传会引发故障的指令

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230219201809930.png" alt="image-20230219201809930" style="zoom:50%;" />



#### 再看fork函数

之前的知识已经告诉我们，父进程和fork的子进程拥有的是两个互不干涉的地址空间

当fork函数被父进程调用时，内核就为子进程创建各种数据结构，并分配了唯一的PID（task_struct），然后为了给这个进程创建虚拟内存，它创建了父进程的mm_struct、vm_area_struct和页表的原样副本给子进程的地址空间（因为父进程和子进程的代码和数据都有一模一样的，区别在于调用fork函数后跳转的部分不同）。并且将两个进程的每个页面都标记为**只读**，每个区域结构都标记为私有的写时复制

这样fork函数在子进程中返回时（即将跳转到与父进程不同的代码段），父进程现在的虚拟内存（调用fork函数时）和子进程的虚拟内存是**一样的**。当这两个进程中任意一个，有写操作时，写时复制机制都会创建新页面，彼此互不影响



#### 再看execve函数

假设在当前进程中执行了如下的execve调用

```c
execve("a.out", NULL, NULL);
```

execve函数在当前进程加载并运行a.out中的程序，用a.out程序替代当前程序，步骤如下：

1. **删除已存在的用户区域**
2. **映射私有区域**：为新程序的代码、数据、bss和栈区域创建新的vm_area_struct，所有的这些区域都是私有的，写时复制的
3. **映射共享区域**
4. **设置程序计数器**：execve的最后一件事就是设置当前程序上下文中的程序计数器，使之指向新代码区域的入口点

<img src="https://cdn.jsdelivr.net/gh/linengcs/note-img@main/uPic/image-20230219203601812.png" alt="image-20230219203601812" style="zoom:67%;" />



#### 使用mmap函数的用户级内存映射

前面提到过的，一个进程可以创建大量的虚拟内存区域，怎么创建呢？Linux进程可以使用mmap函数来创建新的虚拟内存区域，并将对象映射到这些区域

```c
#include <unistd.h>
#include <sys/mman.h>

void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
// 如果成功则返回指向映射区域的指针，如出错则为MAP_FAILED(-1)
```



mmap函数要求内核创建一个新的虚拟内存区域，最好是从地址`start`开始的一个区域，并将文件描述符`fd`指定的对象的一个连续的片映射到这个新区域。连续的片的大小为`length`字节，从距文件开始处偏移量`offset`字节的地方开始。

`start`只是一个暗示，通常设置为NULL

`prot`包含新映射的虚拟区域的访问权限位（vm_area_struct里的vm_prot）

`flags`由描述被映射对象类型的位组成，如果设置了MAP_ANON标记位，那么映射的对象就是一个匿名对象，那么相应的虚拟页面就是请求二进制零的。相应的还有MAP_PRIVATE和MAP_SHARED

例如

```c
bufp = mmap(NULL, size, PROT_READ, MAP_PRIVATE|MAP_ANON, 0, 0);
```

该函数让内核创建了一个size字节的，只读的，私有的，请求二进制零的虚拟内存区域，如果调用成功，bufp包含新区域的地址

mmap函数可以删除虚拟内存的区域

```c
int mmap(void *start, size_t length);
```

删除从虚拟地址start开始的长度为length字节的区域